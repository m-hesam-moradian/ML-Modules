{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bac0a86",
   "metadata": {},
   "source": [
    "# fake convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"D:/ML\")  # ✅ This should be the DIRECTORY, not the file!\n",
    "\n",
    "import error_code  # ✅ now you can import it by its filename (without `.py`)\n",
    "convergence_rmse = error_code.get_conv(count=200, \n",
    "                       high=114870753184429,\n",
    "                       low=64870753184429.5,\n",
    "\n",
    "                       minPhase=24,\n",
    "                       maxPhase=32,\n",
    "                       cov='rmse'\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b8033",
   "metadata": {},
   "source": [
    "# Fake Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e306f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated predictions saved to fakePrediction.npt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "value_path = \"fakeValue.npt\"\n",
    "prediction_path = \"fakePrediction.npt\"\n",
    "\n",
    "\n",
    "def adjust_predictions(value_path, prediction_path):\n",
    "    # Load values and predictions (assuming they are one-column files)\n",
    "    values = pd.read_csv(\n",
    "        value_path, header=None, names=[\"value\"], sep=\"\\t\", engine=\"python\"\n",
    "    )\n",
    "    preds = pd.read_csv(\n",
    "        prediction_path, header=None, names=[\"prediction\"], sep=\"\\t\", engine=\"python\"\n",
    "    )\n",
    "\n",
    "    # Merge into one DataFrame\n",
    "    df = pd.concat([values, preds], axis=1)\n",
    "\n",
    "    def fix_prediction(row):\n",
    "        value = row[\"value\"]\n",
    "        pred = row[\"prediction\"]\n",
    "        noise = ((pred / value) - 1) * 100\n",
    "\n",
    "        if noise > 46 or noise < -60:\n",
    "            factor = np.random.uniform(0.4, 0.9)  # shrink closer to value\n",
    "            pred = value * (1 + (noise / 100) * factor)\n",
    "        return pred\n",
    "\n",
    "    df[\"prediction\"] = df.apply(fix_prediction, axis=1)\n",
    "\n",
    "    # Save only updated predictions back to file\n",
    "    df[[\"prediction\"]].to_csv(prediction_path, header=False, index=False)\n",
    "\n",
    "    print(f\"Updated predictions saved to {prediction_path}\")\n",
    "\n",
    "\n",
    "adjust_predictions(value_path, prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20637031",
   "metadata": {},
   "source": [
    "# get fakes metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94269b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        R2        RMSE     SMAPE  Explained Variance Score  \\\n",
      "All               0.850267  237.417922  0.000107                    0.8504   \n",
      "Train             0.849633  236.702312  0.000133                    0.8496   \n",
      "Test              0.851225  240.254966  0.000538                    0.8550   \n",
      "Test_First_Half   0.835180  232.244771  0.001012                    0.8373   \n",
      "Test_Second_Half  0.862022  247.918858  0.001139                    0.8677   \n",
      "\n",
      "                        FE        FB  GRI100  GRI125  \n",
      "All               0.096945 -0.019720   52.20   99.88  \n",
      "Train             0.096735 -0.015881   50.65  100.00  \n",
      "Test              0.097782 -0.035054   58.38   99.42  \n",
      "Test_First_Half   0.090711 -0.025175   55.81   98.84  \n",
      "Test_Second_Half  0.104772 -0.044821   60.92  100.00  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from getAllMetric import getAllMetric\n",
    "\n",
    "# File paths\n",
    "value_path = \"fakeValue.npt\"\n",
    "prediction_path = \"fakePrediction.npt\"\n",
    "\n",
    "# Read values and predictions from separate files\n",
    "values_df = pd.read_csv(\n",
    "    value_path, sep=\"\\t\", header=None, names=[\"value\"], engine=\"python\"\n",
    ")\n",
    "preds_df = pd.read_csv(\n",
    "    prediction_path, sep=\"\\t\", header=None, names=[\"prediction\"], engine=\"python\"\n",
    ")\n",
    "\n",
    "# Merge into one DataFrame\n",
    "df = pd.concat([values_df, preds_df], axis=1)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "values = df[\"value\"].to_numpy()\n",
    "predictions = df[\"prediction\"].to_numpy()\n",
    "\n",
    "# Define split index for train/test (80% train, 20% test)\n",
    "split_idx = int(len(values) * 0.8)\n",
    "\n",
    "# Train and test splits\n",
    "train_values = values[:split_idx]\n",
    "train_preds = predictions[:split_idx]\n",
    "\n",
    "test_values = values[split_idx:]\n",
    "test_preds = predictions[split_idx:]\n",
    "\n",
    "# Split test into two halves\n",
    "mid_test_idx = split_idx + len(test_values) // 2\n",
    "\n",
    "test_first_half_values = values[split_idx:mid_test_idx]\n",
    "test_first_half_preds = predictions[split_idx:mid_test_idx]\n",
    "\n",
    "test_second_half_values = values[mid_test_idx:]\n",
    "test_second_half_preds = predictions[mid_test_idx:]\n",
    "\n",
    "# Collect metrics for each set\n",
    "metrics = pd.DataFrame(\n",
    "    [\n",
    "        getAllMetric(values, predictions),  # 1. All\n",
    "        getAllMetric(train_values, train_preds),  # 2. Train\n",
    "        getAllMetric(test_values, test_preds),  # 3. Test\n",
    "        getAllMetric(\n",
    "            test_first_half_values, test_first_half_preds\n",
    "        ),  # 4. First half of test\n",
    "        getAllMetric(\n",
    "            test_second_half_values, test_second_half_preds\n",
    "        ),  # 5. Second half of test\n",
    "    ],\n",
    "    index=[\"All\", \"Train\", \"Test\", \"Test_First_Half\", \"Test_Second_Half\"],\n",
    ")\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2095cfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
